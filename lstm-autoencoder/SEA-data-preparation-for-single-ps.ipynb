{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from quantile_norm import quantileNormalize\n",
    "import datetime\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#hyperparameter\n",
    "problem_set = 255116\n",
    "# random sample students\n",
    "student_cnt = 0\n",
    "read_csv = False\n",
    "limit_cnt = 300\n",
    "data_file = str(problem_set)+'_sq_train_data.csv'\n",
    "ps_file = str(problem_set)+'_ps_list'\n",
    "ps = str(problem_set)+'_ps_index'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (21,23,25) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "pl_df = pd.read_csv('this_one_problem_logs_seq.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pl_df['formatted_start_time'] = pd.to_datetime(pl_df['start_time'])\n",
    "\n",
    "date_before = datetime.date(2016, 8, 1)\n",
    "\n",
    "print 'the number of students {}'.format(len(pl_df['user_id'].unique()))\n",
    "\n",
    "pl_df = pl_df[pl_df['formatted_start_time'] < date_before].reset_index()\n",
    "\n",
    "print 'the number of students {}'.format(len(pl_df['user_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of row in train_df 438676\n",
      "number of row in pl_df 7744243\n"
     ]
    }
   ],
   "source": [
    "# read one experiment\n",
    "ps_df = pd.read_csv('~/git/22-Experiments/'+str(problem_set)+'_exp.csv', header=None)\n",
    "\n",
    "sublist = random.sample(pl_df['user_id'].unique(), student_cnt)\n",
    "student_list = sublist + ps_df[1].unique().tolist()\n",
    "\n",
    "train_df = pl_df[pl_df['user_id'].isin(student_list)].reset_index()\n",
    "\n",
    "train_df = train_df[train_df['original'] == 1]\n",
    "\n",
    "print 'number of row in train_df {}'.format(len(train_df))\n",
    "print 'number of row in pl_df {}'.format(len(pl_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "545"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df['user_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "545\n"
     ]
    }
   ],
   "source": [
    "print len(ps_df[1].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315\n"
     ]
    }
   ],
   "source": [
    "if read_csv:\n",
    "    ps_list = []\n",
    "    with open(str(problem_set)+'_ps_list') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line != '-':\n",
    "                ps_list.append(int(line))\n",
    "    mask = train_df['sequence_id'].isin(ps_list)\n",
    "    ps_cnt = len(ps_list)\n",
    "else:\n",
    "    sub_counts = pd.value_counts(train_df['sequence_id'])\n",
    "    ps_cnt = len(sub_counts[sub_counts > limit_cnt])\n",
    "    mask = train_df['sequence_id'].isin(sub_counts[sub_counts > limit_cnt].index)\n",
    "print ps_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(ps_index, 'w') as f:\n",
    "    for ite in sub_counts[sub_counts > limit_cnt].index.tolist():\n",
    "        f.write(str(ite) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ps_index = []\n",
    "with open(str(problem_set)+'_ps_index', 'r') as f:\n",
    "    for line in f:\n",
    "        ps_index.append(int(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prepare(sub_df, one_hot=True):\n",
    "    new_df = pd.DataFrame()\n",
    "    if one_hot:\n",
    "        train_df['sequence_id'][~mask] = \"-\"\n",
    "        sub_df = train_df\n",
    "        new_df = pd.get_dummies(sub_df['sequence_id'])\n",
    "    # u'correct , u'bottom_hint, u'hint_count, u'attempt_count, u'first_response_time, first_action\n",
    "    new_df['user_id'] = sub_df['user_id']\n",
    "    # binary correctness\n",
    "    new_df['correct'] = np.where(sub_df['correct'] < 1, 0, 1)\n",
    "    new_df['bottom_hint'] = sub_df['bottom_hint']\n",
    "    new_df['hint_count'] = sub_df['hint_count']\n",
    "    new_df['attempt_count'] = sub_df['attempt_count']\n",
    "    new_df['first_response_time'] = sub_df['first_response_time']\n",
    "    # first action\n",
    "    new_df['first_action'] = sub_df['first_action']\n",
    "\n",
    "    #norm = lambda x: (x - x.min()) / (x.max() - x.min()) if x.max() - x.min() else x/(x+1)\n",
    "    # normalize within problems\n",
    "    #new_df.insert(len(new_df.columns), 'NofFRT', sub_df.groupby('sequence_id')['first_response_time'].transform(norm))\n",
    "    new_df.insert(len(new_df.columns), 'NofFRT', sub_df.groupby('sequence_id')['first_response_time'].rank(pct=True))\n",
    "    del new_df['first_response_time']\n",
    "\n",
    "    new_df.insert(len(new_df.columns), 'normalized_hint_count', sub_df.groupby('sequence_id')['hint_count'].rank(pct=True))\n",
    "    del new_df['hint_count']\n",
    "\n",
    "    new_df.insert(len(new_df.columns), 'normalized_attempt_count', sub_df.groupby('sequence_id')['attempt_count'].rank(pct=True))\n",
    "    del new_df['attempt_count']\n",
    "    del new_df['user_id']\n",
    "    new_df['sequence_id'] = sub_df['sequence_id']\n",
    "    new_df['user_id'] = sub_df['user_id']\n",
    "    new_df['id'] = sub_df['id']\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_df = prepare(train_df, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def checknull(df):\n",
    "    for column in df.columns:\n",
    "        if df[column].isnull().values.any():\n",
    "            print column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "checknull(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df.to_csv(data_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not read_csv:\n",
    "    with open(ps_file, 'w') as file:\n",
    "        for ite in new_df.columns[:ps_cnt].tolist():\n",
    "            file.write(str(ite) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pl_df = pd.read_csv(str(problem_set)+'_sq_train_data.csv')\n",
    "# group by students\n",
    "pl_df.set_index('id', inplace=True)\n",
    "pl_g = pl_df.groupby('user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pl_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for name, group in pl_g:\n",
    "    for ite in group['sequence_id'].tolist():\n",
    "        print ite\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stats info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cnt_list = []\n",
    "for name,group in sub_df.groupby('user_id'):\n",
    "    cnt_list.append(len(group))\n",
    "\n",
    "print np.mean(cnt_list)\n",
    "print int(np.percentile(cnt_list, 75))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Features (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_complete_df = pd.read_csv('this_one_assignment_start_complete.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_complete_df = start_complete_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_complete_df[start_complete_df['assignment_completed']==1].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sub_df['assignment_id'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "join_df = pd.merge(sub_df, start_complete_df, on=['assignment_id', 'user_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(join_df)\n",
    "print len(sub_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type_df = pd.read_csv('this_one_assignment_type.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "type_df = type_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "join2_df = pd.merge(join_df, type_df, on=['assignment_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "join2_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(join2_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pc_df = pd.read_csv('this_one_problem_correctness.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pc_df = pc_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "join3_df = pd.merge(join2_df, pc_df, on=['problem_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "join3_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(join3_df)\n",
    "print len(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "join3_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del new_df['user_id']\n",
    "del new_df['id']\n",
    "new_df['assignment_completed'] = join3_df['assignment_completed']\n",
    "new_df['is_flat_skill_builder'] = join3_df['is_flat_skill_builder']\n",
    "new_df['textbook_items'] = join3_df['textbook_items']\n",
    "new_df['certified_problem_solving_items'] = join3_df['certified_problem_solving_items']\n",
    "new_df['correctness'] = join3_df['correctness']\n",
    "new_df['user_id'] = join3_df['user_id']\n",
    "new_df['id'] = join3_df['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df['correctness'].fillna(0.5, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df['assignment_completed'].fillna(0, inplace=True)\n",
    "new_df['is_flat_skill_builder'].fillna(0, inplace=True)\n",
    "new_df['textbook_items'].fillna(0, inplace=True)\n",
    "new_df['certified_problem_solving_items'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in new_df.columns:\n",
    "    if new_df[col].isnull().values.any():\n",
    "        print col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(str(problem_set)+'_ps_list', 'w') as file:\n",
    "    for ite in new_df.columns[:ps_cnt].tolist():\n",
    "        file.write(str(ite) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_df.to_csv(str(problem_set)+'_extra_pl_train_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
